{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef907a-3000-42fc-909b-f92203c09b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. A company conducted a survey of its employees and found that 70% of the employees use the companys health insurance plan, while 40% of\n",
    "    the employees who use the plan are smokers. \n",
    "    What is the probability that an employee is a smoker given that he/she uses the health insurance plan?\n",
    "    \n",
    "    \n",
    "    probability that an employee is a smoker given that they use the health insurance plan, you can use conditional probability. \n",
    "    \n",
    "    In this case, you want to calculate:-\n",
    "\n",
    "        P(Smoker ∣ Uses Health Insurance Plan) = ?\n",
    "        \n",
    "    P(A|B) = P(A and B) / P(B)\n",
    "    \n",
    "    In this case:-\n",
    "\n",
    "        A --> represents being a smoker.\n",
    "        B --> represents using the health insurance plan.\n",
    "\n",
    "        \n",
    "    P(Uses Health Insurance Plan) = 0.70 (70% of employees use the plan)\n",
    "    P(Smoker ∣ Uses Health Insurance Plan) = 0.40 (40% of plan users are smokers)\n",
    "    \n",
    "    P(Smoker∣Uses Health Insurance Plan) = P(Smoker and Uses Health Insurance Plan) / P(Uses Health Insurance Plan)\n",
    "                                        = (0.40×0.70) / 0.70\n",
    "    P(Smoker∣Uses Health Insurance Plan) = 0.40\n",
    "    \n",
    "    So, the probability that an employee is a smoker given that they use the health insurance plan is 40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc2040-7f87-4d09-863e-e0967dcd559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n",
    "\n",
    "\n",
    "     Difference between Bernoulli Naive Bayes and Multinomial Naive Bayes:\n",
    "\n",
    "        Bernoulli Naive Bayes:-\n",
    "        \n",
    "            Designed for binary data, where features are either 0 (absence) or 1 (presence), often used in document classification tasks.\n",
    "            \n",
    "        Multinomial Naive Bayes:-\n",
    "        \n",
    "            Suitable for discrete count or frequency data, commonly used in text classification with features like word counts or term frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b26bce5-0df4-4f77-bc89-66ad6d98a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How does Bernoulli Naive Bayes handle missing values?\n",
    "\n",
    "\n",
    "    Bernoulli Naive Bayes can treat missing values in two ways:-\n",
    "    \n",
    "       (i). It can consider missing values as a separate category alongside 0 and 1, treating them as a third possible value for a feature.\n",
    "        \n",
    "        (ii). Alternatively, you can impute missing values using methods like mean, median, or mode imputation to convert them into 0s or 1s,\n",
    "                making the data suitable for Bernoulli Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad41134-fe44-4402-9022-9a1f27dddb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Can Gaussian Naive Bayes be used for multi-class classification?\n",
    "\n",
    "\n",
    "    (i). Yes, Gaussian Naive Bayes can be used for multi-class classification tasks.\n",
    "\n",
    "    (ii). Gaussian Naive Bayes is appropriate when features are continuous and follow a Gaussian (normal) distribution.\n",
    "\n",
    "    (iii). It estimates Gaussian distribution parameters (mean and variance) for each classs features and uses Bayes theorem \n",
    "           to classify new data into one of the multiple classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2389b31-9532-443d-ac72-1e920955761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Assignment:\n",
    "    Data preparation:\n",
    "        \n",
    "        Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
    "        datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "        is spam or not based on several input features.\n",
    "        \n",
    "    Implementation:\n",
    "        \n",
    "        Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "        scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "        dataset. You should use the default hyperparameters for each classifier.\n",
    "        \n",
    "    Results:\n",
    "        \n",
    "        Report the following performance metrics for each classifier:\n",
    "        Accuracy\n",
    "        Precision\n",
    "        Recall\n",
    "        F1 score\n",
    "        \n",
    "    Discussion:\n",
    "        \n",
    "        Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
    "        the case? Are there any limitations of Naive Bayes that you observed?\n",
    "        \n",
    "    Conclusion:\n",
    "        \n",
    "Summarise your findings and provide some suggestions for future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdff120e-bff2-4eb9-9dfd-18e5f777b66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_%3B</th>\n",
       "      <th>char_freq_%28</th>\n",
       "      <th>char_freq_%5B</th>\n",
       "      <th>char_freq_%21</th>\n",
       "      <th>char_freq_%24</th>\n",
       "      <th>char_freq_%23</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_%3B  char_freq_%28  \\\n",
       "0             0.00            0.00  ...           0.00          0.000   \n",
       "1             0.00            0.94  ...           0.00          0.132   \n",
       "2             0.64            0.25  ...           0.01          0.143   \n",
       "3             0.31            0.63  ...           0.00          0.137   \n",
       "4             0.31            0.63  ...           0.00          0.135   \n",
       "\n",
       "   char_freq_%5B  char_freq_%21  char_freq_%24  char_freq_%23  \\\n",
       "0            0.0          0.778          0.000          0.000   \n",
       "1            0.0          0.372          0.180          0.048   \n",
       "2            0.0          0.276          0.184          0.010   \n",
       "3            0.0          0.137          0.000          0.000   \n",
       "4            0.0          0.135          0.000          0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  class  \n",
       "0                       278      1  \n",
       "1                      1028      1  \n",
       "2                      2259      1  \n",
       "3                       191      1  \n",
       "4                       191      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "data = pd.read_csv('spambase_csv.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "786871f3-6d7b-49a8-b926-ee95ed9f4745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes:\n",
      "Accuracy: 0.8839380364047911\n",
      "Precision: 0.8869617393737383\n",
      "Recall: 0.8152389047416673\n",
      "F1 Score: 0.8481249015095276\n",
      "\n",
      "Multinomial Naive Bayes:\n",
      "Accuracy: 0.7863496180326323\n",
      "Precision: 0.7393175533565436\n",
      "Recall: 0.7214983911116508\n",
      "F1 Score: 0.7282909724016348\n",
      "\n",
      "Gaussian Naive Bayes:\n",
      "Accuracy: 0.8217730830896915\n",
      "Precision: 0.7103733928118492\n",
      "Recall: 0.9569516119239877\n",
      "F1 Score: 0.8130660909542995\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "data = pd.read_csv('spambase_csv.csv')\n",
    "data.head()\n",
    "\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']  \n",
    "\n",
    "# Implementation of Naive Bayes Classifiers\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Evaluate each variant of Naive Bayes classifiers using 10-fold cross-validation\n",
    "\n",
    "# Bernoulli Naive Bayes:-\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "accuracy_bnb = cross_val_score(bnb, X, y, cv=10, scoring='accuracy')\n",
    "precision_bnb = cross_val_score(bnb, X, y, cv=10, scoring='precision')\n",
    "recall_bnb = cross_val_score(bnb, X, y, cv=10, scoring='recall')\n",
    "f1_score_bnb = cross_val_score(bnb, X, y, cv=10, scoring='f1')\n",
    "\n",
    "# Multinomial Naive Bayes:\n",
    "mnb = MultinomialNB()\n",
    "accuracy_mnb = cross_val_score(mnb, X, y, cv=10, scoring='accuracy')\n",
    "precision_mnb = cross_val_score(mnb, X, y, cv=10, scoring='precision')\n",
    "recall_mnb = cross_val_score(mnb, X, y, cv=10, scoring='recall')\n",
    "f1_score_mnb = cross_val_score(mnb, X, y, cv=10, scoring='f1')\n",
    "\n",
    "# Gaussian Naive Bayes:\n",
    "gnb = GaussianNB()\n",
    "accuracy_gnb = cross_val_score(gnb, X, y, cv=10, scoring='accuracy')\n",
    "precision_gnb = cross_val_score(gnb, X, y, cv=10, scoring='precision')\n",
    "recall_gnb = cross_val_score(gnb, X, y, cv=10, scoring='recall')\n",
    "f1_score_gnb = cross_val_score(gnb, X, y, cv=10, scoring='f1')\n",
    "\n",
    "# Report the performance metrics for each classifier\n",
    "print(\"Bernoulli Naive Bayes:\")\n",
    "print(\"Accuracy:\", accuracy_bnb.mean())\n",
    "print(\"Precision:\", precision_bnb.mean())\n",
    "print(\"Recall:\", recall_bnb.mean())\n",
    "print(\"F1 Score:\", f1_score_bnb.mean())\n",
    "\n",
    "print(\"\\nMultinomial Naive Bayes:\")\n",
    "print(\"Accuracy:\", accuracy_mnb.mean())\n",
    "print(\"Precision:\", precision_mnb.mean())\n",
    "print(\"Recall:\", recall_mnb.mean())\n",
    "print(\"F1 Score:\", f1_score_mnb.mean())\n",
    "\n",
    "print(\"\\nGaussian Naive Bayes:\")\n",
    "print(\"Accuracy:\", accuracy_gnb.mean())\n",
    "print(\"Precision:\", precision_gnb.mean())\n",
    "print(\"Recall:\", recall_gnb.mean())\n",
    "print(\"F1 Score:\", f1_score_gnb.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85ad36b-5e87-4354-b397-688c614c541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Based on the performance metrics we have heres a discussion of the results and some observations:-\n",
    "\n",
    "Bernoulli Naive Bayes:\n",
    "\n",
    "Accuracy: 88.39%\n",
    "Precision: 88.70%\n",
    "Recall: 81.52%\n",
    "F1 Score: 84.81%\n",
    "\n",
    "\n",
    "Multinomial Naive Bayes:\n",
    "\n",
    "Accuracy: 78.63%\n",
    "Precision: 73.93%\n",
    "Recall: 72.15%\n",
    "F1 Score: 72.83%\n",
    "\n",
    "\n",
    "Gaussian Naive Bayes:\n",
    "\n",
    "Accuracy: 82.18%\n",
    "Precision: 71.04%\n",
    "Recall: 95.70%\n",
    "F1 Score: 81.31%\n",
    "\n",
    "\n",
    "Discussion:-\n",
    "\n",
    "    Among the three Naive Bayes variants, Bernoulli Naive Bayes achieved the highest accuracy, precision, and F1 score. \n",
    "    \n",
    "    It performed well in distinguishing between spam and non-spam emails.\n",
    "    \n",
    "    Multinomial Naive Bayes, while having a lower accuracy than Bernoulli Naive Bayes, still demonstrated reasonable performance in classifying emails.\n",
    "    \n",
    "    Gaussian Naive Bayes showed a high recall rate, indicating that it is good at identifying spam emails (fewer false negatives). \n",
    "    \n",
    "    However, it had a lower precision compared to the other two, leading to a lower F1 score.\n",
    "    \n",
    "Observations:-\n",
    "\n",
    "    Bernoulli Naive Bayes is suitable when the features are binary or binary-like (e.g., presence or absence of words in text classification).\n",
    "    \n",
    "    Multinomial Naive Bayes is typically used for discrete data, often in text classification where features represent word counts.\n",
    "    \n",
    "    Gaussian Naive Bayes assumes that features follow a Gaussian distribution, which may not hold for all types of data.\n",
    "    \n",
    "Limitations:-\n",
    "\n",
    "    Naive Bayes classifiers assume independence between features, which may not always hold in real-world data.\n",
    "    \n",
    "    The choice of Naive Bayes variant should be based on the nature of the data and problem requirements.\n",
    "    \n",
    "    These results represent the performance with default hyperparameters; fine-tuning and feature engineering may further improve performance.\n",
    "    \n",
    "Conclusion:-\n",
    "\n",
    "    In this evaluation, Bernoulli Naive Bayes performed the best overall in classifying spam and non-spam emails.\n",
    "    \n",
    "    Multinomial Naive Bayes also showed reasonable performance.\n",
    "    \n",
    "    Gaussian Naive Bayes had high recall but lower precision, which might not be ideal for all applications.\n",
    "    \n",
    "    The choice of the most suitable Naive Bayes variant depends on the specific characteristics of the data and the desired trade-offs between precision,\n",
    "    recall, and overall accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
