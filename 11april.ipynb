{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c124b54-e1bb-4a15-a69e-42f2e687406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is an ensemble technique in machine learning?\n",
    "\n",
    "\n",
    "       (i). An ensemble technique in machine learning is a method that combines the predictions of multiple base models to produce a single,\n",
    "            more robust and accurate prediction. \n",
    "\n",
    "        (ii). The idea behind ensemble techniques is that by aggregating the predictions from multiple models, the overall performance can be improved,\n",
    "              often surpassing the performance of individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5655f9b9-722c-46b8-b206-37939db4dced",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Why are ensemble techniques used in machine learning?\n",
    "\n",
    "\n",
    "    Ensemble techniques are used in machine learning for several reasons:-\n",
    "\n",
    "        (i). They can improve predictive accuracy by reducing overfitting and bias.\n",
    "    \n",
    "        (ii). They are robust and can handle noisy or incomplete data.\n",
    "    \n",
    "        (iii). They can capture different aspects of the data by combining diverse models.\n",
    "    \n",
    "        (iv). They provide a better generalization of the problem by reducing variance.\n",
    "    \n",
    "        (v). They are versatile and can be applied to various types of machine learning tasks, such as classification, regression, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de04d02b-4c1d-41fe-a973-aa510dd9de4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is bagging?\n",
    "\n",
    "\n",
    "        (i). Bagging, short for Bootstrap Aggregating, is an ensemble technique that involves training multiple base models (usually of the same type)\n",
    "             on different bootstrap samples of the training data and then aggregating their predictions. \n",
    "\n",
    "        (ii). Bagging aims to reduce variance and improve the stability of the model by averaging or taking a majority vote of the individual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd5cbaf-6663-43e2-a13a-fba0bc5822e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What is boosting?\n",
    "\n",
    "\n",
    "       (i). Boosting is another ensemble technique that aims to improve the performance of a machine learning model by combining the predictions of multiple weak \n",
    "        base models (typically decision trees) sequentially. \n",
    "\n",
    "        (ii). In boosting, each base model is trained to correct the errors made by the previous models, leading to a strong overall model. \n",
    "\n",
    "        (iii). Common boosting algorithms include AdaBoost, Gradient Boosting, and XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bb00a2-ba19-401f-a4d5-868a092b015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What are the benefits of using ensemble techniques?\n",
    "\n",
    "\n",
    "    The benefits of using ensemble techniques in machine learning include:-\n",
    "\n",
    "        (i). Improved predictive accuracy and generalization.\n",
    "        \n",
    "        (ii). Reduced overfitting and increased model robustness.\n",
    "        \n",
    "        (iii). Enhanced model stability and robustness to noisy data.\n",
    "        \n",
    "        (iv). The ability to capture complex relationships in the data.\n",
    "        \n",
    "        (v). Versatility, as ensemble methods can be applied to various machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0e0d75-af0d-4813-81a6-4b852fb6fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Are ensemble techniques always better than individual models?\n",
    "\n",
    "\n",
    "    (i). Ensemble techniques are not always better than individual models. \n",
    "    \n",
    "    (ii). Their effectiveness depends on the specific problem, the quality of the base models, and the diversity among them.\n",
    "\n",
    "    (iii). In some cases, a well-tuned individual model may perform as well as or even better than an ensemble. \n",
    "    \n",
    "    (iv). Ensembles are particularly useful when dealing with complex, noisy, or high-dimensional data, where combining multiple models can improve overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ba0784-7aeb-4510-a6f0-47da18ff423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. How is the confidence interval calculated using bootstrap?\n",
    "\n",
    "\n",
    "    The confidence interval using bootstrap is calculated by resampling the data with replacement to create a large number of bootstrap samples.\n",
    "    For each bootstrap sample, you calculate the statistic of interest (e.g., mean, median) and create a distribution of these statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4454fa4f-acf1-4cb1-8d07-b61f6598cffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. How does bootstrap work and What are the steps involved in bootstrap?\n",
    "\n",
    "\n",
    "    Bootstrap is a resampling technique used to estimate the sampling distribution of a statistic or parameter. \n",
    "    \n",
    "    Here are the steps involved in the bootstrap process:-\n",
    "\n",
    "        (i). Randomly draw a sample (with replacement) of the same size as the original data from the dataset. This creates a bootstrap sample.\n",
    "        \n",
    "        (ii). Calculate the statistic of interest (e.g., mean, median) for the bootstrap sample.\n",
    "        \n",
    "        (iii). Repeat steps 1 and 2 a large number of times (typically thousands of times) to create a distribution of the statistic.\n",
    "        \n",
    "        (iv). Construct the confidence interval by finding the desired percentiles of the distribution. For example, for a 95% confidence interval,\n",
    "              we can use the 2.5th and 97.5th percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0faee67-1e48-472d-87b6-5014cd736f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. A researcher wants to estimate the mean height of a population of trees. They measure the height of a\n",
    "    sample of 50 trees and obtain a mean height of 15 meters and a standard deviation of 2 meters. Use\n",
    "    bootstrap to estimate the 95% confidence interval for the population mean height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b611f0c5-d260-4049-b772-ede86649a994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: (15.00, 15.00) meters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "sample_heights = np.array([15.0] * 50)  # Replace with actual data\n",
    "\n",
    "# Number of bootstrap samples\n",
    "num_samples = 10000\n",
    "\n",
    "bootstrap_means = np.zeros(num_samples)\n",
    "\n",
    "# Generate bootstrap samples and calculate means\n",
    "for i in range(num_samples):\n",
    "    bootstrap_sample = np.random.choice(sample_heights, size=50, replace=True)\n",
    "    bootstrap_means[i] = np.mean(bootstrap_sample)\n",
    "\n",
    "# Calculate 95% confidence interval\n",
    "lower_percentile = np.percentile(bootstrap_means, 2.5)\n",
    "upper_percentile = np.percentile(bootstrap_means, 97.5)\n",
    "\n",
    "print(f\"95% Confidence Interval: ({lower_percentile:.2f}, {upper_percentile:.2f}) meters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
