{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33d50b0a-1f26-4ff3-b7ac-6fa6b05a4737",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" align=\"center\" style=\"padding: 10px;\">\n",
    "<h1><b><u>Web Scrapping</u></b></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f6d1a4-4437-4a4c-afd8-f80ba2ebfeac",
   "metadata": {},
   "source": [
    "#### **Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.** ####\n",
    "\n",
    "**Web Scraping:**\n",
    "\n",
    "Web scraping is the process of extracting data from websites using automated tools or scripts. It involves fetching web pages, parsing the HTML or XML content, and extracting the desired information. Web scraping enables users to retrieve large amounts of data from various websites efficiently and quickly, saving time and effort.\n",
    "\n",
    "**Areas where Web Scraping is used to get data:**\n",
    "\n",
    "1. **Data Extraction:** Web scraping is commonly used to extract data from websites, including product information, news articles, social media content, and more.\n",
    "\n",
    "2. **Automation:** It is used to automate data retrieval and update processes, such as stock prices, weather data, or sports scores.\n",
    "\n",
    "3. **Competitive Analysis:** Companies use web scraping to gather competitive intelligence, monitor prices and offerings of competitors, and stay informed about market trends.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Q2. What are the different methods used for Web Scraping?** ####\n",
    "\n",
    "The different methods used for web scraping include manual copy-pasting, regular expressions (Regex), HTML parsing with libraries like BeautifulSoup, CSS selectors, XPath, and web scraping libraries/frameworks such as Scrapy and Puppeteer.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Q3. What is Beautiful Soup? Why is it used?** ####\n",
    "\n",
    "**Beautiful Soup** is a Python library used for parsing HTML or XML documents and extracting specific data. It simplifies the process of web scraping by providing easy navigation through the document structure, data extraction methods, and data cleaning functionality. It is beginner-friendly and integrates well with other web scraping tools and libraries.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Q4. Why is Flask used in this Web Scraping project?** ####\n",
    "\n",
    "**Flask** is used in web scraping projects for its capabilities in web application development, data visualization, handling asynchronous requests, API development, task scheduling, and customization. It provides a flexible and efficient framework for building user interfaces, presenting data, and automating the scraping process.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Q5. Write the names of AWS services used in this project. Also, explain the use of each service.** ####\n",
    "\n",
    "**AWS services used in this project are:**\n",
    "\n",
    "1. **Elastic Beanstalk:**\n",
    "\n",
    "    - Easily deploy and manage your web applications without worrying about the underlying infrastructure.\n",
    "    - Automatically handle capacity provisioning, load balancing, and application health monitoring.\n",
    "    - Support applications developed in various programming languages and frameworks.\n",
    "    - Enable quick scaling to handle increased traffic or workload demands.\n",
    "    - Integrate with other AWS services for enhanced functionality and flexibility.\n",
    "\n",
    "2. **Code Pipeline:**\n",
    "\n",
    "    - Build a continuous delivery workflow.\n",
    "    - Integrate with various development tools.\n",
    "    - Automate software release processes.\n",
    "\n",
    "3. **Identity and Access Management (IAM):**\n",
    "\n",
    "    - Create and manage user accounts.\n",
    "    - Manage security credentials.\n",
    "    - Use roles for temporary access.\n",
    "    - Integrate with other AWS services.\n",
    "    - Audit and monitor access.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
