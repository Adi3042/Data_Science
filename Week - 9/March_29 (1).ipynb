{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eee5c7b1-2966-4c2e-bfbe-e0dbd16aa6fa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" align=\"center\" style=\"padding: 10px;\">\n",
    "    <h1><b><u>Regression-4</u></b></h1>\n",
    "</div>\n",
    "\n",
    "**Q1. What is Lasso Regression, and how does it differ from other regression techniques?**\n",
    "**Lasso Regression (Least Absolute Shrinkage and Selection Operator):**\n",
    "- It is a linear regression technique used for both prediction and feature selection.\n",
    "- Differs from other regression techniques, such as ordinary least squares (OLS) regression and Ridge Regression, in its regularization method.\n",
    "- Lasso adds a penalty term to the linear regression objective function, which is the sum of squared residuals.\n",
    "- This penalty term is proportional to the absolute values of the regression coefficients, causing some coefficients to become exactly zero. As a result, Lasso performs automatic feature selection by effectively eliminating less important features from the model.\n",
    "---\n",
    "**Q2. What is the main advantage of using Lasso Regression in feature selection?**\n",
    "**Main advantage of using Lasso Regression in feature selection:**\n",
    "- Automatic Feature Selection\n",
    "- Simplifies the Model\n",
    "- Reduces Overfitting\n",
    "- Handles Multicollinearity\n",
    "- Improved Model Interpretability\n",
    "- Enhanced Computational Efficiency\n",
    "- Customizable Regularization Strength\n",
    "- Useful for High-Dimensional Data\n",
    "- Feature Ranking\n",
    "- Robust to Outliers\n",
    "---\n",
    "**Q3. How do you interpret the coefficients of a Lasso Regression model?**\n",
    "**Interpretation of the coefficients in a Lasso Regression model:**\n",
    "- Non-Zero Coefficients Signify Importance\n",
    "- Linear Relationship\n",
    "- Feature Selection\n",
    "- Elimination of Irrelevant Features\n",
    "- Enhanced Model Interpretability\n",
    "- Coefficient Magnitude Indicates Impact\n",
    "- Sparse Model\n",
    "- Facilitates Feature Ranking\n",
    "- Useful for Feature Engineering\n",
    "- Automatic Variable Importance Assessment\n",
    "The interpretation of coefficients in Lasso Regression is straightforward: non-zero coefficients indicate the selected and important features, while zero coefficients represent the features that have been effectively removed from the model. This feature selection property makes Lasso Regression particularly useful for building simpler, more interpretable models while improving predictive performance.\n",
    "---\n",
    "**Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?**\n",
    "- In Lasso Regression, the primary tuning parameter is the regularization strength, often denoted as lambda (λ).\n",
    "- Lambda controls the amount of penalty applied to the absolute values of the regression coefficients.\n",
    "- A larger λ results in more coefficients being pushed to zero, leading to stronger feature selection.\n",
    "- A smaller λ allows more coefficients to remain non-zero, potentially resulting in a model closer to OLS regression.\n",
    "Choosing the right value of λ is crucial, and it can be determined through techniques like cross-validation.\n",
    "---\n",
    "**Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?**\n",
    "Lasso Regression is primarily designed for linear regression problems, which means it models linear relationships between features and the target variable.\n",
    "However, it can be extended for non-linear regression by first transforming the input features or creating new features that capture non-linear relationships. For example, you can include polynomial features, interaction terms, or apply other non-linear transformations to the input features to make the problem amenable to Lasso Regression.\n",
    "---\n",
    "**Q6. What is the difference between Ridge Regression and Lasso Regression?**\n",
    "**Difference between Ridge Regression and Lasso Regression:**\n",
    "- Regularization Types:\n",
    "  - Ridge Regression adds a penalty term based on the sum of squared coefficients (L2 regularization).\n",
    "  - Lasso Regression adds a penalty term based on the sum of absolute values of coefficients (L1 regularization).\n",
    "- Coefficient Shrinkage:\n",
    "  - Ridge Regression tends to shrink coefficients towards zero, but it rarely makes them exactly zero.\n",
    "  - Lasso Regression can drive some coefficients to exactly zero, effectively performing feature selection.\n",
    "- Feature Selection:\n",
    "  - Ridge Regression retains all features but reduces their impact, making it less effective for feature selection.\n",
    "  - Lasso Regression automatically selects a subset of features by setting some coefficients to zero, facilitating feature selection.\n",
    "- Multicollinearity Handling:\n",
    "  - Ridge Regression is effective in mitigating multicollinearity by reducing the impact of correlated features.\n",
    "  - Lasso Regression not only reduces multicollinearity but also performs feature selection by eliminating some correlated features.\n",
    "- Complexity vs. Sparsity:\n",
    "  - Ridge Regression typically results in a model with non-zero coefficients for all features, preserving model complexity.\n",
    "  - Lasso Regression often leads to a sparse model with only a subset of non-zero coefficients, promoting model simplicity.\n",
    "---\n",
    "**Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?**\n",
    "Yes, Lasso Regression can handle multicollinearity in input features to some extent. Lasso's feature selection property helps mitigate multicollinearity by automatically selecting one of the correlated features while setting others to zero. This simplifies the model and reduces multicollinearity's impact.\n",
    "However, it is essential to note that Lasso may not completely eliminate multicollinearity but can address it partially by selecting the most relevant features.\n",
    "---\n",
    "**Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?**\n",
    "We can use techniques like grid search or randomized search to efficiently explore a range of λ values. The goal is to find the λ that balances model complexity (number of non-zero coefficients) and predictive accuracy, which is typically determined by minimizing the validation set's error.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
